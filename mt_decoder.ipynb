{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a1cb960-f61c-475f-acd2-07dd9c3cd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from Preprocessing import PreProcessor\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding,\n",
    "    Dropout,\n",
    "    LayerNormalization,\n",
    "    Dense,\n",
    "    MultiHeadAttention,\n",
    ")\n",
    "from Preprocessing import PreProcessor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "388ad910-1d40-4e86-8963-02deae9ecab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(max_len, d_model)\n",
    "        \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
    "        # Apply sin to even positions and cos to odd positions\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81772af0-26cb-4a51-983f-7ee2ec8398fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalBert:\n",
    "    def __init__(self):\n",
    "        # Use the fine-tuned Legal BERT model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "        self.model = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "        \n",
    "        # Extend the positional embeddings\n",
    "        self.extend_positional_embeddings(self.model, new_max_position_embeddings=4096)\n",
    "\n",
    "    def extend_positional_embeddings(self, model, new_max_position_embeddings):\n",
    "        \"\"\"\n",
    "        Extends the positional embeddings of the model.\n",
    "\n",
    "        Parameters: \n",
    "        model (transformers.PreTrainedModel): The model whose positional embeddings are to be extended.\n",
    "        new_max_position_embeddings (int): The new maximum length for positional embeddings.\n",
    "        \"\"\"\n",
    "        # Set the new max position embeddings in the model config\n",
    "        model.config.max_position_embeddings = new_max_position_embeddings\n",
    "        \n",
    "        # Resize the position_ids and position_embeddings\n",
    "        old_embeddings = model.embeddings.position_embeddings.weight\n",
    "        old_num_embeddings, embedding_dim = old_embeddings.size()\n",
    "        \"\"\"\n",
    "        Extends the positional embeddings of the model.\n",
    "\n",
    "        Parameters: \n",
    "        model (transformers.PreTrainedModel): The model whose positional embeddings are to be extended.\n",
    "        new_max_position_embeddings (int): The new maximum length for positional embeddings.\n",
    "        \"\"\"\n",
    "        # Create new positional embeddings matrix\n",
    "        new_embeddings = torch.nn.Embedding(new_max_position_embeddings, embedding_dim)\n",
    "        \n",
    "        # Initialize the new embeddings with the original values\n",
    "        new_embeddings.weight.data[:old_num_embeddings, :] = old_embeddings.data\n",
    "\n",
    "        # Initialize the remaining embeddings (if any) with a uniform distribution\n",
    "        if new_max_position_embeddings > old_num_embeddings:\n",
    "            new_embeddings.weight.data[old_num_embeddings:, :] = torch.nn.init.uniform_(torch.empty(new_max_position_embeddings - old_num_embeddings, embedding_dim))\n",
    "\n",
    "        # Replace the model's position embeddings with the new extended ones\n",
    "        model.embeddings.position_embeddings = new_embeddings\n",
    "        \n",
    "        # Resize position_ids to match the new max position embeddings\n",
    "        model.embeddings.position_ids = torch.arange(new_max_position_embeddings).expand((1, -1))\n",
    "\n",
    "\n",
    "    def get_context_vectors(self, text):\n",
    "        \"\"\"\n",
    "        Tokenizes and encodes text using the Legal BERT model.\n",
    "\n",
    "        Parameters: \n",
    "        text (str): The text to be tokenized and encoded.\n",
    "\n",
    "        Returns: torch.Tensor\n",
    "            The output hidden states from the model.\n",
    "        \"\"\"\n",
    "        # Tokenize and encode text with the Legal BERT model\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=4096)\n",
    "        outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d92ba8f5-158b-45b6-b470-2468787e4753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"positional_encoding_5_1/add:0\", shape=(None, None, 768), dtype=float32)\n",
      "Tensor(\"positional_encoding_5_1/add:0\", shape=(None, None, 768), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ modified_standard_decoder_5   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8000</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">50,875,456</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ModifiedStandardDecoder</span>)     │                           │                 │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_16 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ modified_standard_decoder_5   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8000\u001b[0m)        │      \u001b[38;5;34m50,875,456\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mModifiedStandardDecoder\u001b[0m)     │                           │                 │ input_layer_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,875,456</span> (194.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,875,456\u001b[0m (194.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,875,456</span> (194.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,875,456\u001b[0m (194.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ModifiedStandardDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_heads, ff_dim, dropout_rate=0.1, **kwargs):\n",
    "        super(ModifiedStandardDecoder, self).__init__(**kwargs)\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.positional_encoding = PositionalEncoding(embedding_dim)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "        self.masked_self_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, dropout=dropout_rate)\n",
    "        self.layer_norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.multihead_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, dropout=dropout_rate)\n",
    "        self.layer_norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(embedding_dim)\n",
    "        ])\n",
    "        self.layer_norm3 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout3 = Dropout(dropout_rate)\n",
    "        self.dense = Dense(vocab_size)\n",
    "        self.softmax = tf.keras.activations.softmax\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, padding_mask=None):\n",
    "        # Text embedding layer\n",
    "        embedded = self.embedding(inputs)\n",
    "\n",
    "        # Dropout\n",
    "        embedded = self.dropout1(embedded)\n",
    "\n",
    "        # Positional encoding\n",
    "        embedded = self.positional_encoding(embedded)\n",
    "\n",
    "        # Dropout\n",
    "        embedded = self.dropout2(embedded)\n",
    "\n",
    "        print(embedded)\n",
    "\n",
    "        # Create look-ahead mask\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        look_ahead_mask = self.create_look_ahead_mask(seq_len)\n",
    "        look_ahead_mask = tf.convert_to_tensor(look_ahead_mask, dtype=tf.float32)\n",
    "        look_ahead_mask = look_ahead_mask[tf.newaxis, tf.newaxis, :, :]  # Shape: (1, 1, seq_len, seq_len)\n",
    "\n",
    "        # Masked multi-head self-attention\n",
    "        attention_output = self.masked_self_attention(query=embedded, key=embedded, value=embedded, attention_mask=look_ahead_mask)\n",
    "\n",
    "        # Layer normalization\n",
    "        attention_output = self.layer_norm1(attention_output + embedded)\n",
    "\n",
    "        # Multi-head attention with encoder output\n",
    "        output = self.multihead_attention(query=attention_output, key=encoder_outputs, value=encoder_outputs, attention_mask=padding_mask)\n",
    "\n",
    "        # Layer normalization\n",
    "        output = self.layer_norm2(output + attention_output)\n",
    "\n",
    "        # Feed-forward network\n",
    "        ffn_output = self.ffn(output)\n",
    "\n",
    "        # Layer normalization\n",
    "        ffn_output = self.layer_norm3(ffn_output + output)\n",
    "\n",
    "        # Dropout\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "\n",
    "        # Dense layer\n",
    "        logits = self.dense(ffn_output)\n",
    "\n",
    "        # Softmax\n",
    "        predictions = self.softmax(logits)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def create_look_ahead_mask(self, size):\n",
    "        mask = tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "        return mask\n",
    "\n",
    "    def save(self,filename):\n",
    "        self.model.save('bert_model_{}.h5'.format(filename))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ModifiedStandardDecoder, self).get_config()\n",
    "        config.update({\n",
    "            \"vocab_size\": self.embedding.input_dim,\n",
    "            \"embedding_dim\": self.embedding.output_dim,\n",
    "            \"num_heads\": self.masked_self_attention.num_heads,\n",
    "            \"ff_dim\": self.ffn.layers[0].units,\n",
    "            \"dropout_rate\": self.dropout1.rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Example usage\n",
    "vocab_size = 8000\n",
    "embedding_dim = 768\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "dropout_rate = 0.1\n",
    "\n",
    "decoder = ModifiedStandardDecoder(vocab_size, embedding_dim, num_heads, ff_dim, dropout_rate)\n",
    "\n",
    "annotated_inputs = tf.keras.Input(shape=(None,))\n",
    "encoder_outputs = tf.keras.Input(shape=(None, embedding_dim))\n",
    "\n",
    "padding_mask = None  # Add padding mask if necessary\n",
    "\n",
    "outputs = decoder(annotated_inputs, encoder_outputs, padding_mask=padding_mask)\n",
    "model = tf.keras.Model(inputs=[annotated_inputs, encoder_outputs], outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8084fa79-44d3-413e-b1bd-6036b298bede",
   "metadata": {},
   "source": [
    "# Encoder Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b182deb5-c7dc-49cb-a3d9-112a118b3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = [\"John Doe a lawyer at ABC Corporation filed a lawsuit on January in New York City\", \n",
    "           \"Mama mo a dentist at DFC Corporation filed a lawsuit on January in New York City\"]\n",
    "\n",
    "ruling = ['John Doe a lawyer at ABC Corporation', 'Mama mo a dentist at DFC Corporation']\n",
    "    \n",
    "# Initialize the preprocessor and legal BERT\n",
    "legal_bert = LegalBert()\n",
    "\n",
    "bert_output = legal_bert.get_context_vectors(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a344f1c-2b85-4c51-8b94-5129091acb1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Display BERT output shape\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocesed Result:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mpreprocessed_result\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens_no_stopwords\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERT Encoding Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bert_output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERT Encoding:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bert_output)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_result' is not defined"
     ]
    }
   ],
   "source": [
    "# Display BERT output shape\n",
    "print(\"Preprocesed Result:\", len(preprocessed_result['tokens_no_stopwords']))\n",
    "print(\"BERT Encoding Shape:\", bert_output.shape)\n",
    "print(\"BERT Encoding:\", bert_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608cb28f-c5b6-48d3-a256-a9073f90ae5c",
   "metadata": {},
   "source": [
    "# Decoder Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f2fd0-4d99-48fe-8d14-6dc687dd0270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"segments = pd.DataFrame({\n",
    "    'text': \"John Doe, a lawyer at ABC Corporation, filed a lawsuit on January 5, 2022, in New York City.\",\n",
    "    'ruling': [['John', 'Doe', 'a', 'lawyer', 'at', 'ABC', 'Corporation']]\n",
    "})\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a826cbe-3d0a-4660-a7a2-9c120ed09ba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msegments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "segments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b743ac86-26b3-45a4-8569-ac6d76961961",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"segments = [['John', 'Doe', 'a', 'lawyer', 'at', 'ABC', 'Corporation']]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35a0243a-e30d-4778-89fe-26f3941e1a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 20, 768])\n",
      "(2, 7)\n",
      "Epoch 1/5\n",
      "Tensor(\"functional_17_1/modified_standard_decoder_5_1/dropout_31_1/stateless_dropout/SelectV2:0\", shape=(None, 7, 768), dtype=float32)\n",
      "Tensor(\"functional_17_1/modified_standard_decoder_5_1/dropout_31_1/stateless_dropout/SelectV2:0\", shape=(None, 7, 768), dtype=float32)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 9.2683\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.2857 - loss: 5.1693\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.2857 - loss: 4.6780\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.2857 - loss: 3.4315\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.0714 - loss: 3.8120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22a16c62f90>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the segments\n",
    "tokenizer = Tokenizer(num_words=8000)  # Adjust num_words according to your vocabulary size\n",
    "tokenizer.fit_on_texts(segments)\n",
    "tokenized_segments = tokenizer.texts_to_sequences(ruling)\n",
    "\n",
    "# Pad the sequences to ensure uniform length\n",
    "padded_segments = pad_sequences(tokenized_segments, padding='post')\n",
    "\n",
    "# Convert to tensor\n",
    "padded_segments = tf.convert_to_tensor(padded_segments)\n",
    "\n",
    "print(bert_output.shape)\n",
    "print(padded_segments.shape)\n",
    "\n",
    "# Ensure xtrain and ytrain have the same batch size\n",
    "assert bert_output.shape[0] == padded_segments.shape[0]\n",
    "\n",
    "xtrain = bert_output.detach().numpy()\n",
    "ytrain = padded_segments\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit([ytrain, xtrain], ytrain, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f3063-e88f-4579-8be4-0bab506dd263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
