{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a1cb960-f61c-475f-acd2-07dd9c3cd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding,\n",
    "    Dropout,\n",
    "    LayerNormalization,\n",
    "    Dense,\n",
    "    MultiHeadAttention,\n",
    ")\n",
    "from Preprocessing import PreProcessor\n",
    "from TopicSegmentation import LegalBert\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9bfa2cc-bf67-4271-b745-9a175ae6e340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdfl0\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "text = \"John Doe, a lawyer at ABC Corporation, filed a lawsuit on January 5, 2022, in New York City.\"\n",
    "\n",
    "# Initialize the preprocessor and legal BERT\n",
    "preprocessor = PreProcessor()\n",
    "legal_bert = LegalBert()\n",
    "\n",
    "# Preprocess the text\n",
    "preprocessed_result = preprocessor.preprocess(text)\n",
    "\n",
    "# Display preprocessing results\n",
    "#print(\"Tokens:\", preprocessed_result['tokens'])\n",
    "#print(\"Tokens without stopwords:\", preprocessed_result['tokens_no_stopwords'])\n",
    "\n",
    "# Get BERT encoding for the preprocessed text without stopwords\n",
    "#bert_output = legal_bert.get_context_vectors(preprocessed_result['tokens_no_stopwords'])\n",
    "\n",
    "# Display BERT output shape\n",
    "#print(\"Legal BERT's context vector:\", bert_output)\n",
    "#print(\"Legal BERT's context vector shape:\", bert_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388ad910-1d40-4e86-8963-02deae9ecab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, max_len=16000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(max_len, d_model)\n",
    "        \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
    "        # Apply sin to even positions and cos to odd positions\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92ba8f5-158b-45b6-b470-2468787e4753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdfl0\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:188: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Tensor(\"positional_encoding_1/add:0\", shape=(None, None, 128), dtype=float32)\n",
      "Tensor(\"positional_encoding_1/add:0\", shape=(None, None, 128), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ modified_standard_decoder     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8000</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,243,456</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ModifiedStandardDecoder</span>)     │                           │                 │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ modified_standard_decoder     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8000\u001b[0m)        │       \u001b[38;5;34m3,243,456\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│ (\u001b[38;5;33mModifiedStandardDecoder\u001b[0m)     │                           │                 │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,243,456</span> (12.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,243,456\u001b[0m (12.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,243,456</span> (12.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,243,456\u001b[0m (12.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ModifiedStandardDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_heads, ff_dim, dropout_rate=0.1, **kwargs):\n",
    "        super(ModifiedStandardDecoder, self).__init__(**kwargs)\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.positional_encoding = PositionalEncoding(embedding_dim)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "        self.masked_self_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, dropout=dropout_rate)\n",
    "        self.layer_norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.multihead_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, dropout=dropout_rate)\n",
    "        self.layer_norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(embedding_dim)\n",
    "        ])\n",
    "        self.layer_norm3 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout3 = Dropout(dropout_rate)\n",
    "        self.dense = Dense(vocab_size)\n",
    "        self.softmax = tf.keras.activations.softmax\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, padding_mask=None):\n",
    "        # Text embedding layer\n",
    "        embedded = self.embedding(inputs)\n",
    "\n",
    "        # Dropout\n",
    "        embedded = self.dropout1(embedded)\n",
    "\n",
    "        # Positional encoding\n",
    "        embedded = self.positional_encoding(embedded)\n",
    "\n",
    "        # Dropout\n",
    "        embedded = self.dropout2(embedded)\n",
    "\n",
    "        print(embedded)\n",
    "\n",
    "        # Create look-ahead mask\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        look_ahead_mask = self.create_look_ahead_mask(seq_len)\n",
    "        look_ahead_mask = tf.convert_to_tensor(look_ahead_mask, dtype=tf.float32)\n",
    "        look_ahead_mask = look_ahead_mask[tf.newaxis, tf.newaxis, :, :]  # Shape: (1, 1, seq_len, seq_len)\n",
    "\n",
    "        # Masked multi-head self-attention\n",
    "        attention_output = self.masked_self_attention(query=embedded, key=embedded, value=embedded, attention_mask=look_ahead_mask)\n",
    "\n",
    "        # Layer normalization\n",
    "        attention_output = self.layer_norm1(attention_output + embedded)\n",
    "\n",
    "        # Multi-head attention with encoder output\n",
    "        output = self.multihead_attention(query=attention_output, key=encoder_outputs, value=encoder_outputs, attention_mask=padding_mask)\n",
    "\n",
    "        # Layer normalization\n",
    "        output = self.layer_norm2(output + attention_output)\n",
    "\n",
    "        # Feed-forward network\n",
    "        ffn_output = self.ffn(output)\n",
    "\n",
    "        # Layer normalization\n",
    "        ffn_output = self.layer_norm3(ffn_output + output)\n",
    "\n",
    "        # Dropout\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "\n",
    "        # Dense layer\n",
    "        logits = self.dense(ffn_output)\n",
    "\n",
    "        # Softmax\n",
    "        predictions = self.softmax(logits)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def create_look_ahead_mask(self, size):\n",
    "        mask = tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "        return mask\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ModifiedStandardDecoder, self).get_config()\n",
    "        config.update({\n",
    "            \"vocab_size\": self.embedding.input_dim,\n",
    "            \"embedding_dim\": self.embedding.output_dim,\n",
    "            \"num_heads\": self.masked_self_attention.num_heads,\n",
    "            \"ff_dim\": self.ffn.layers[0].units,\n",
    "            \"dropout_rate\": self.dropout1.rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Example usage\n",
    "vocab_size = 8000\n",
    "embedding_dim = 128\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "dropout_rate = 0.1\n",
    "\n",
    "decoder = ModifiedStandardDecoder(vocab_size, embedding_dim, num_heads, ff_dim, dropout_rate)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None,))\n",
    "encoder_outputs = tf.keras.Input(shape=(None, embedding_dim))\n",
    "\n",
    "padding_mask = None  # Add padding mask if necessary\n",
    "\n",
    "outputs = decoder(inputs, encoder_outputs, padding_mask=padding_mask)\n",
    "model = tf.keras.Model(inputs=[inputs, encoder_outputs], outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e22f2fd0-4d99-48fe-8d14-6dc687dd0270",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"John Doe, a lawyer at ABC Corporation, filed a lawsuit on January 5, 2022, in New York City.\"\n",
    "segments = pd.DataFrame({\n",
    "    'text': \"John Doe, a lawyer at ABC Corporation, filed a lawsuit on January 5, 2022, in New York City.\",\n",
    "    'ruling': [['John', 'Doe', 'a', 'lawyer', 'at', 'ABC', 'Corporation']],\n",
    "    'facts': [['filed', 'a', 'lawsuit', 'on', 'January']],\n",
    "    'issues': [['in', 'New', 'York', 'City']]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4c11755-6783-43d8-a005-43b056b5a025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ruling</th>\n",
       "      <th>facts</th>\n",
       "      <th>issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Doe, a lawyer at ABC Corporation, filed a...</td>\n",
       "      <td>[John, Doe, a, lawyer, at, ABC, Corporation]</td>\n",
       "      <td>[filed, a, lawsuit, on, January]</td>\n",
       "      <td>[in, New, York, City]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  John Doe, a lawyer at ABC Corporation, filed a...   \n",
       "\n",
       "                                         ruling  \\\n",
       "0  [John, Doe, a, lawyer, at, ABC, Corporation]   \n",
       "\n",
       "                              facts                 issues  \n",
       "0  [filed, a, lawsuit, on, January]  [in, New, York, City]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35a0243a-e30d-4778-89fe-26f3941e1a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(padded_segments\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Ensure xtrain and ytrain have the same batch size\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m bert_output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m padded_segments\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     21\u001b[0m xtrain \u001b[38;5;241m=\u001b[39m bert_output\n\u001b[0;32m     22\u001b[0m ytrain \u001b[38;5;241m=\u001b[39m padded_segments\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tokenize the segments\n",
    "tokenizer = Tokenizer(num_words=8000)  # Adjust num_words according to your vocabulary size\n",
    "tokenizer.fit_on_texts(segments)\n",
    "tokenized_segments = tokenizer.texts_to_sequences(segments)\n",
    "\n",
    "# Get context vector of the whole document\n",
    "bert_output = legal_bert.get_context_vectors(preprocessed_result['tokens_no_stopwords'])\n",
    "\n",
    "# Pad the sequences to ensure uniform length\n",
    "padded_segments = pad_sequences(tokenized_segments, padding='post')\n",
    "\n",
    "# Convert to tensor\n",
    "padded_segments = tf.convert_to_tensor(padded_segments)\n",
    "\n",
    "print(bert_output.shape[0])\n",
    "print(padded_segments.shape[1])\n",
    "\n",
    "# Ensure xtrain and ytrain have the same batch size\n",
    "assert bert_output.shape[0] == padded_segments.shape[1]\n",
    "\n",
    "xtrain = bert_output\n",
    "ytrain = padded_segments\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(xtrain, ytrain, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a39ca4-9de0-4842-9734-eb9128202dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
