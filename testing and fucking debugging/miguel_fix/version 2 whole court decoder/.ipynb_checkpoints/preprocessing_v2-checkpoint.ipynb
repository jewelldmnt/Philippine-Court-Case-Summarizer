{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe31d63-600e-40f5-b0a9-475567e5787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdfl0\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import  sent_tokenize\n",
    "from transformers import Trainer, TrainingArguments, LEDTokenizer, LEDForConditionalGeneration, AutoModel, LEDConfig\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import transformers\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59f034e-1eaf-4a4a-8973-5ca5f169f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess:\n",
    "    def __init__(self, file_path):\n",
    "        # Tokenization and cleaning related variable\n",
    "        self.regex_tokenizer = RegexpTokenizer(r\"[a-zA-Z0-9]+|\\.(?![a-zA-Z0-9])\")\n",
    "        self.stopwords = ['the','of','to']\n",
    "        \n",
    "        # Model related variables\n",
    "        self.LED_tokenizer = LEDTokenizer.from_pretrained(\"allenai/led-base-16384\")\n",
    "        self.config = LEDConfig.from_pretrained('allenai/led-base-16384')\n",
    "        self.config.max_decoder_position_embeddings = 512\n",
    "        self.decoder_max_token = 512\n",
    "        self.config.max_encoder_position_embeddings = 4096\n",
    "        self.encoder_max_token = 4096\n",
    "        self.LED_model = LEDForConditionalGeneration(self.config)\n",
    "        self.global_mask = []\n",
    "\n",
    "        # Data related variables\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.court_cases = []\n",
    "        self.rulings = []\n",
    "        self.issues = []\n",
    "        self.facts = []\n",
    "        self.led_court = []\n",
    "\n",
    "        # Actual Data input to the model\n",
    "        self.encoder_inputs = []\n",
    "        self.decoder_inputs = []\n",
    "        self.final_data = []\n",
    "\n",
    "        # Unknown token variables\n",
    "        try:\n",
    "            with open('unknown_tokens.txt', 'r') as f:\n",
    "                self.unknown_tokens = f.read().splitlines()\n",
    "        except:\n",
    "            self.unknown_tokens = []\n",
    "        self.found_new_unknown_token = False\n",
    "\n",
    "        # Preprocess and prepare raw data\n",
    "        self.df.dropna(inplace=True)\n",
    "        self.df = self.df.drop_duplicates()\n",
    "        self.preprocess()\n",
    "        self.find_unknown_token()\n",
    "        if self.found_new_unknown_token:\n",
    "            self.add_tokens_tokenizer_model()\n",
    "        self.add_specialtoken_globalmask()\n",
    "        self.prepare_LED_data()\n",
    "\n",
    "    def return_model_tokenizer_data(self):\n",
    "        train_data, eval_data = train_test_split(self.final_data, test_size=0.1, random_state=42)\n",
    "        return self.LED_model, self.LED_tokenizer, train_data, eval_data\n",
    "\n",
    "    def return_visualization_data(self):\n",
    "        return self.court_cases, self.rulings, self.issues, self.facts\n",
    "\n",
    "    def prepare_LED_data(self):\n",
    "        # length of encoder and decoder inputs are the same and should be a list of strings\n",
    "        for i in range(len(self.encoder_inputs)):\n",
    "            # Tokenize the input (court case text)\n",
    "            inputs = self.LED_tokenizer(self.encoder_inputs[i], \n",
    "                               max_length=self.encoder_max_token, \n",
    "                               padding=\"max_length\", \n",
    "                               truncation=True, \n",
    "                               return_tensors=\"pt\")\n",
    "            \n",
    "            # Tokenize the issues (segmentation)\n",
    "            outputs = self.LED_tokenizer(self.decoder_inputs[i], \n",
    "                                max_length=self.decoder_max_token,\n",
    "                                padding=\"max_length\", \n",
    "                                truncation=True, \n",
    "                                return_tensors=\"pt\")\n",
    "\n",
    "            # prepare court case input ids\n",
    "            encoder_input_ids = inputs.input_ids\n",
    "            attention_mask = inputs.attention_mask\n",
    "\n",
    "            # prepare decoder input ids\n",
    "            decoder_input_ids = outputs.input_ids.clone()\n",
    "\n",
    "            # ensure global_attention_mask is padded to the correct length\n",
    "            global_attention_mask = self.global_mask[i]\n",
    "            if len(global_attention_mask) < self.encoder_max_token:\n",
    "                padding_length = self.encoder_max_token - len(global_attention_mask)\n",
    "                global_attention_mask = global_attention_mask + [0] * padding_length\n",
    "    \n",
    "            global_attention_mask = torch.tensor(global_attention_mask).unsqueeze(0)  # convert to tensor and match input shape\n",
    "            print('encoder_input_ids: ',len(encoder_input_ids[0]))\n",
    "            print('decoder_input_ids: ',len(decoder_input_ids[0]))\n",
    "            print('global_attention_mask: ',len(global_attention_mask[0])) # debugging here'''\n",
    "\n",
    "            '''print('encoder_input_ids: ',self.encoder_inputs[i])\n",
    "            print('decoder_input_ids: ',self.decoder_inputs[i]) \n",
    "            print('global_attention_mask: ',global_attention_mask)# debugging here'''\n",
    "\n",
    "            '''print(\"Input IDs shape:\", encoder_input_ids.shape)\n",
    "            print(\"Attention Mask shape:\", attention_mask.shape)\n",
    "            print(\"Global Attention Mask shape:\", global_attention_mask.shape)\n",
    "            print(\"Labels shape:\", decoder_input_ids.shape) # debugging here'''\n",
    "\n",
    "            # prepare final data structure\n",
    "            data = {\n",
    "                \"input_ids\": encoder_input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "                \"global_attention_mask\": global_attention_mask,\n",
    "                \"labels\": decoder_input_ids\n",
    "            }\n",
    "\n",
    "            # append final data\n",
    "            self.final_data.append(data)\n",
    "        \n",
    "        \n",
    "    def add_specialtoken_globalmask(self):\n",
    "        '''\n",
    "        Add special tokens to the segment when it switches labels. Add global mask to the first 3 tokens of the start of each segment.\n",
    "        \n",
    "        Example: \"<RULING> the courts ruling is in this text. this text is also about ruling. \n",
    "        <ISSUES> this text is about issue. <FACTS> this text is facts. <RULING> this is a text for ruling. <FACTS> this text is also facts.\"\n",
    "        '''\n",
    "        # Prepare encoder/decoder inputs and global attention mask\n",
    "        current_label = ''\n",
    "        for i in range(len(self.court_cases)):\n",
    "            sentences = self.court_cases[i]\n",
    "            list_encoder = []\n",
    "            list_decoder = []\n",
    "            list_attntn = []\n",
    "            '''print(\"sentences:\", sentences) #debugging here'''\n",
    "            \n",
    "            for sentence in sentences:  # process each sentence one by one\n",
    "                # Tokenize each sentence\n",
    "                token = self.regex_tokenizer.tokenize(sentence)\n",
    "                global_attntn = []\n",
    "\n",
    "                if sentence in self.facts[i]:\n",
    "                    list_encoder.append(' '.join(token))\n",
    "\n",
    "                    if current_label != \"<FACTS>\" and len(token) >= 7:\n",
    "                        # Add special token and set global attention for the first 3 tokens\n",
    "                        token = [\"<FACTS>\"] + token\n",
    "                        global_attntn = [1] * 3 + [0] * (len(token) - 3)\n",
    "                        current_label = \"<FACTS>\"\n",
    "                    else:\n",
    "                        global_attntn = [0] * len(token)\n",
    "\n",
    "                    # Append to decoder inputs and global mask\n",
    "                    list_decoder.append(' '.join(token))\n",
    "                    list_attntn.append(global_attntn)\n",
    "\n",
    "                elif sentence in self.rulings[i]:\n",
    "                    list_encoder.append(' '.join(token))\n",
    "                    if current_label != \"<RULING>\" and len(token) >= 7:\n",
    "                        # Add special token and set global attention for the first 3 tokens\n",
    "                        token = [\"<RULING>\"] + token\n",
    "                        global_attntn = [1] * 4 + [0] * (len(token) - 4)\n",
    "                        current_label = \"<RULING>\"\n",
    "                    else:\n",
    "                        global_attntn = [0] * len(token)\n",
    "\n",
    "                    # Append to decoder inputs and global mask\n",
    "                    list_decoder.append(' '.join(token))\n",
    "                    list_attntn.append(global_attntn)\n",
    "\n",
    "                elif sentence in self.issues[i]:\n",
    "                    list_encoder.append(' '.join(token))\n",
    "                    if current_label != \"<ISSUES>\" and len(token) >= 7:\n",
    "                        # Add special token and set global attention for the first 2 tokens\n",
    "                        token = [\"<ISSUES>\"] + token\n",
    "                        global_attntn = [1] * 2 + [0] * (len(token) - 2)\n",
    "                        current_label = \"<ISSUES>\"\n",
    "                    else:\n",
    "                        global_attntn = [0] * len(token)\n",
    "\n",
    "                    # Append to decoder inputs and global mask\n",
    "                    list_decoder.append(' '.join(token))\n",
    "                    list_attntn.append(global_attntn)\n",
    "                else:\n",
    "                    list_encoder.append(' '.join(token))\n",
    "                    if current_label != \"<RULING>\" and len(token) >= 7:\n",
    "                        # Add special token and set global attention for the first 3 tokens\n",
    "                        token = [\"<RULING>\"] + token\n",
    "                        global_attntn = [1] * 4 + [0] * (len(token) - 4)\n",
    "                        current_label = \"<RULING>\"\n",
    "                    else:\n",
    "                        global_attntn = [0] * len(token)\n",
    "\n",
    "                    # Append to decoder inputs and global mask\n",
    "                    list_decoder.append(' '.join(token))\n",
    "                    list_attntn.append(global_attntn)\n",
    "\n",
    "            # Flatten the list of list of tokens and attentions\n",
    "            self.encoder_inputs.append(' '.join(list_encoder))\n",
    "            self.decoder_inputs.append(' '.join(list_decoder))\n",
    "            self.global_mask.append([attntn for attntns in list_attntn for attntn in attntns])\n",
    "\n",
    "    def add_tokens_tokenizer_model(self):\n",
    "        '''\n",
    "        Add unknown token including special tokens to the tokenizer and resize the token embedding of the model.\n",
    "        '''\n",
    "        # Add special tokens if not in tokenizer\n",
    "        special_tokens = ['<RULING>', '<ISSUES>', '<FACTS>']\n",
    "        if not set(special_tokens).issubset(set(self.unknown_tokens)):\n",
    "            self.unknown_tokens.extend(special_tokens)\n",
    "\n",
    "        # Add the new tokens to the tokenizer\n",
    "        self.tokenizer.add_tokens(self.unknown_tokens)\n",
    "\n",
    "        # Resize the model's token embeddings to match the new tokenizer length\n",
    "        self.LED_model.resize_token_embeddings(len(self.tokenizer))\n",
    "        \n",
    "\n",
    "    def find_unknown_token(self):\n",
    "        '''\n",
    "        Iterate over each cases, converting the tokens into IDs. Check if there is an unknown token in input_ids\n",
    "        '''\n",
    "        for case_tokens in self.court_cases:\n",
    "            input_ids = self.LED_tokenizer.convert_tokens_to_ids(case_tokens)\n",
    "            for input_id in input_ids:\n",
    "                if input_ids == 100 and input_ids not in self.unknown_tokens:\n",
    "                    print(case_tokens[i],\" : \",input_ids[i])\n",
    "                    self.found_new_unknown_token = True\n",
    "                    self.unknown_tokens.append(case_tokens[i])\n",
    "\n",
    "    def preprocess(self):\n",
    "        '''\n",
    "        Clean characters and tokenize court cases and segments.\n",
    "        '''\n",
    "        # Lowercase the text and Remove unnecessary characters\n",
    "        self.court_cases = [self.change_char(text.lower()) for text in self.df[\"whole_text\"]]\n",
    "        self.rulings = [self.change_char(text.lower()) for text in self.df[\"ruling\"]]\n",
    "        self.facts = [self.change_char(text.lower()) for text in self.df[\"facts\"]]\n",
    "        self.issues = [self.change_char(text.lower()) for text in self.df[\"issues\"]]\n",
    "        \n",
    "        # Tokenize the text, storing words and numbers only\n",
    "        self.court_cases = [self.regex_tokenizer.tokenize(text) for text in self.court_cases]\n",
    "        self.rulings = [self.regex_tokenizer.tokenize(text) for text in self.rulings]\n",
    "        self.facts = [self.regex_tokenizer.tokenize(text) for text in self.facts]\n",
    "        self.issues = [self.regex_tokenizer.tokenize(text) for text in self.issues]\n",
    "\n",
    "        # Remove stopwords\n",
    "        self.court_cases = [self.removestop(token_list) for token_list in self.court_cases]\n",
    "        self.rulings = [self.removestop(token_list) for token_list in self.rulings]\n",
    "        self.facts = [self.removestop(token_list) for token_list in self.facts]\n",
    "        self.issues = [self.removestop(token_list) for token_list in self.issues]\n",
    "\n",
    "        # Add a filter to accept only lists with tokens lower than 8192\n",
    "        indices_to_remove = []\n",
    "        for i in range(len(self.court_cases)):\n",
    "            if len(self.court_cases[i]) > self.encoder_max_token:\n",
    "                indices_to_remove.append(i)\n",
    "        \n",
    "        # Remove elements from all lists based on indices_to_remove\n",
    "        for i in reversed(indices_to_remove):\n",
    "            self.court_cases.pop(i)\n",
    "            self.rulings.pop(i)\n",
    "            self.facts.pop(i)\n",
    "            self.issues.pop(i)\n",
    "\n",
    "        # Join tokens to form full strings for each case\n",
    "        self.court_cases = [' '.join(token) for token in self.court_cases]\n",
    "        self.rulings = [' '.join(token) for token in self.rulings]\n",
    "        self.facts = [' '.join(token) for token in self.facts]\n",
    "        self.issues = [' '.join(token) for token in self.issues]\n",
    "    \n",
    "        # Split into sentences\n",
    "        self.court_cases = [sent_tokenize(text) for text in self.court_cases] # text is the whole court case\n",
    "        self.rulings = [sent_tokenize(text) for text in self.rulings]\n",
    "        self.facts = [sent_tokenize(text) for text in self.facts]\n",
    "        self.issues = [sent_tokenize(text) for text in self.issues]\n",
    "\n",
    "    def removestop(self, token_list):\n",
    "        \"\"\"\n",
    "        Remove stopwords from a list of tokens. Handles case where stopwords are in lower case.\n",
    "        \"\"\"\n",
    "        return [token for token in token_list if token.lower() not in self.stopwords]\n",
    "\n",
    "    def change_char(self, text):\n",
    "        \"\"\"\n",
    "        Cleans up text by removing or replacing certain characters and patterns.\n",
    "    \n",
    "        Args:\n",
    "            text: A string to be cleaned.\n",
    "    \n",
    "        Returns:\n",
    "            A cleaned version of the string.\n",
    "        \"\"\"\n",
    "        # More specific substitutions first\n",
    "        #text = re.sub(r\"r.a.\", \"ra \", text, flags=re.IGNORECASE)    # Replace \"R.A.\" with \"ra\"\n",
    "        text = re.sub(r\"section (\\d+)\\.\", r\"section \\1\", text) # Replace \"section N.\" with \"section N\" where N is a number\n",
    "        text = re.sub(r\"sec.\", r\"sec\", text) # Replace \"section N.\" with \"section N\" where N is a number\n",
    "        text = re.sub(r\"p.d.\", r\"pd\", text) # Replace \".d.\" with \"pd\" where N is a number\n",
    "        text = re.sub(r\"\\bno.\\b\", r\"number\", text) # Replace \"no.\" to \"number\"\n",
    "        text = re.sub(r\"\\brtc\\b\", \"regional trial court\", text)  # Replace \"rtc\" with \"regional trial court\"\n",
    "        \n",
    "        # Remove unwanted characters, but keep periods at the end of words\n",
    "        text = re.sub(r\"[(),'\\\"’”\\[\\]]\", \" \", text)   # Remove specific punctuation\n",
    "    \n",
    "        # Remove stray or special characters\n",
    "        text = re.sub(r\"[“”]\", \" \", text)              # Remove “ and ”\n",
    "        text = re.sub(r\"\\u2033\", \" \", text)            # Remove double prime (″)\n",
    "        text = re.sub(r\"\\u2032\", \" \", text)            # Remove prime (′)\n",
    "        \n",
    "        # Remove specific meaningless characters\n",
    "        text = re.sub(r\"\\bg\\b\", \" \", text)\n",
    "        text = re.sub(r\"\\br\\b\", \" \", text)\n",
    "    \n",
    "        # Return cleaned text\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fbae39a-859c-4f5a-906d-1ceaad4989b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n",
      "encoder_input_ids:  4096\n",
      "decoder_input_ids:  512\n",
      "global_attention_mask:  4096\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data, model, and tokenizer before training\n",
    "preprocessor = preprocess('new_court_cases.csv')\n",
    "LED_model, LED_tokenizer, train_data, eval_data = preprocessor.return_model_tokenizer_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914ce92-a2a4-4eed-99d5-6cad8653da80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
