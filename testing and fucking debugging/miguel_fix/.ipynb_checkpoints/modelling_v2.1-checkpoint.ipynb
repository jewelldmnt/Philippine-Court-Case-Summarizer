{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55944bb4-9e10-495d-993d-0c4f5c76bd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdfl0\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60c48f8-fec6-4e07-a077-a04e17d6a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AdamW\n",
    "import time\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cde5205-b4ae-4af8-9ee1-d6a506a3d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f76bb581-ddcd-4a8b-84fd-ed801259fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_to_model_inputs(batch):\n",
    "    # tokenize the inputs and labels\n",
    "    inputs = tokenizer(\n",
    "        batch[\"encoder_input_string\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=4096,\n",
    "    )\n",
    "    outputs = tokenizer(\n",
    "        batch[\"decoder_input_string\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=4096,\n",
    "    )\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    batch[\"labels\"] = outputs.input_ids\n",
    "\n",
    "    # We have to make sure that the PAD token is ignored\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
    "        for labels in batch[\"labels\"]\n",
    "    ]\n",
    "    # Ensure global attention mask is padded to 4096 tokens\n",
    "    for i in range(len(batch[\"globalmask\"])):\n",
    "        if len(batch[\"globalmask\"][i]) > 4096:\n",
    "            # Truncate if the length is greater than 4096\n",
    "            batch[\"globalmask\"][i] = batch[\"globalmask\"][i][:4096]\n",
    "        elif len(batch[\"globalmask\"][i]) < 4096:\n",
    "            # Pad if the length is less than 4096\n",
    "            padding_length = 4096 - len(batch[\"globalmask\"][i])\n",
    "            batch[\"globalmask\"][i] += [0] * padding_length\n",
    "\n",
    "    batch[\"global_attention_mask\"] = batch[\"globalmask\"]\n",
    "\n",
    "    return batch\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(\n",
    "        predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"]\n",
    "    )[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a6567bb-f002-4d4a-8c11-c634ab16c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdfl0\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data, model, and tokenizer before training\n",
    "preprocessor = preprocess('new_court_cases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d09700f-8402-48e0-ae0f-ab234b8d5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = preprocessor.LED_model\n",
    "tokenizer = preprocessor.LED_tokenizer\n",
    "xdata = preprocessor.encoder_inputs\n",
    "ydata = preprocessor.decoder_inputs\n",
    "globalmask = preprocessor.global_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6717d3ab-702c-45f4-8534-5c65118109a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'encoder_input_string': xdata,\n",
    "    'decoder_input_string': ydata,\n",
    "    'globalmask': globalmask\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "599f471a-c484-422b-93b9-734753a89038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder_input_string</th>\n",
       "      <th>decoder_input_string</th>\n",
       "      <th>globalmask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this case is about need for prosection and all...</td>\n",
       "      <td>&lt;RULING&gt; this case is about need for prosectio...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this case is about proof required establish do...</td>\n",
       "      <td>this case is about proof required establish do...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>court resolves instant appeal by certiorari fi...</td>\n",
       "      <td>&lt;FACTS&gt; court resolves instant appeal by certi...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a petition for certiorari petition und...</td>\n",
       "      <td>&lt;FACTS&gt; this is a petition for certiorari peti...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>. . number 230391 petitioner juliette gomez ro...</td>\n",
       "      <td>&lt;FACTS&gt; . . number 230391 petitioner juliette ...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                encoder_input_string  \\\n",
       "0  this case is about need for prosection and all...   \n",
       "1  this case is about proof required establish do...   \n",
       "2  court resolves instant appeal by certiorari fi...   \n",
       "3  this is a petition for certiorari petition und...   \n",
       "4  . . number 230391 petitioner juliette gomez ro...   \n",
       "\n",
       "                                decoder_input_string  \\\n",
       "0  <RULING> this case is about need for prosectio...   \n",
       "1  this case is about proof required establish do...   \n",
       "2  <FACTS> court resolves instant appeal by certi...   \n",
       "3  <FACTS> this is a petition for certiorari peti...   \n",
       "4  <FACTS> . . number 230391 petitioner juliette ...   \n",
       "\n",
       "                                          globalmask  \n",
       "0  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02355a85-321e-4f3b-99ec-51470874691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, eval_data = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "eval_data = eval_data.reset_index(drop=True)\n",
    "train_data = Dataset.from_pandas(train_data)\n",
    "eval_data = Dataset.from_pandas(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f1f7940-9215-4fe6-8c5e-1b16112349b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd99f85bee3494a9c0280f160f466de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/147 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1741607b71934acd8a9320644a8606d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_data.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=2,\n",
    "    remove_columns=[\"encoder_input_string\", \"decoder_input_string\", \"globalmask\"]\n",
    ")\n",
    "\n",
    "val_dataset = eval_data.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=2,\n",
    "    remove_columns=[\"encoder_input_string\", \"decoder_input_string\", \"globalmask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a75079a-9505-43c0-b82d-1b710f8b3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
    ")\n",
    "val_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebf77d5a-0e43-4a41-9417-b34514384984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "4096\n",
      "4096\n",
      "4096\n"
     ]
    }
   ],
   "source": [
    "print(max([len(input_ids) for input_ids in train_dataset['input_ids']]))\n",
    "print(max([len(labels) for labels in train_dataset['labels']]))\n",
    "print(max([len(labels) for labels in train_dataset['global_attention_mask']]))\n",
    "print(max([len(labels) for labels in train_dataset['attention_mask']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c45fd20-c74f-48b9-a677-3a34aa768521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "4096\n"
     ]
    }
   ],
   "source": [
    "print(model.config.max_encoder_position_embeddings)\n",
    "print(model.config.max_decoder_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbf7be74-d1a4-4240-b141-bc6dafaceed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEDConfig {\n",
      "  \"_name_or_path\": \"./\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"LEDForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_window\": [\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_decoder_position_embeddings\": 4096,\n",
      "  \"max_encoder_position_embeddings\": 4096,\n",
      "  \"model_type\": \"led\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.45.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc64309b-4fac-4ac6-af2e-14ac899c68cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdfl0\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    fp16=True,\n",
    "    output_dir=\"./\",\n",
    "    logging_steps=5,\n",
    "    eval_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1070b64-eb76-4273-ad10-910704eaa61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a30e6-0e7f-4273-9321-12872d267595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/18 : < :, Epoch 0.05/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be335d82-3715-40dc-9a25-fa7ce026c15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
