{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1d801-6222-4c27-a67e-dc8e1782f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953d4a7-11f9-43ff-a683-469b67c35a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2bb11-fca1-4223-b8da-fc23c0ceed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LEDTokenizer.from_pretrained(\"allenai/led-base-16384\")\n",
    "model = LEDForConditionalGeneration.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False)\n",
    "file_path = 'new_court_cases.csv'\n",
    "# Prepare the data, model, and tokenizer before training\n",
    "preprocessor = preprocess(file_path)\n",
    "ready_model, ready_tokenizer, ready_data = preprocessor.return_model_tokenizer_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131d046-5c55-4478-be52-90d9230f84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc0dee3-5f9b-427e-ac23-89f4ba5e55bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelling:\n",
    "    def __init__(self, model, tokenizer, data, epochs=3):\n",
    "        self.data = data\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Move the model to the GPU\n",
    "        self.model.to(self.device)\n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        self.model.config.use_cache = False\n",
    "\n",
    "        self.optimizer = AdamW(self.model.parameters(), lr=5e-5)  # Adjust learning rate as needed\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)  # Ignore padding tokens in loss\n",
    "\n",
    "        # Instantiate the dataset and DataLoader\n",
    "        self.dataset = dataset(data=self.data)  # Replace with actual preprocessed data\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=2, shuffle=True)  # Adjust batch size\n",
    "\n",
    "    def finetune(self):\n",
    "        self.model.train()  # Put model in training mode\n",
    "\n",
    "        global_step = 0  # To track the number of steps globally\n",
    "        start_time = time.time()  # Track start time for runtime calculation\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss = 0\n",
    "            for batch in self.dataloader:\n",
    "                global_step += 1\n",
    "                \n",
    "                # Move all batch elements to the correct device (GPU/CPU)\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                global_attention_mask = batch[\"global_attention_mask\"].to(self.device)\n",
    "                issues_ids = batch[\"issues_input_ids\"].to(self.device)\n",
    "                facts_ids = batch[\"facts_input_ids\"].to(self.device)\n",
    "                rulings_ids = batch[\"ruling_input_ids\"].to(self.device)\n",
    "\n",
    "                # Squeeze the extra dimension (dim=1)\n",
    "                input_ids = input_ids.squeeze(1) \n",
    "                issues_ids = issues_ids.squeeze(1)\n",
    "                global_attention_mask = global_attention_mask.squeeze(1) \n",
    "                attention_mask = attention_mask.squeeze(1)\n",
    "                \n",
    "                # Step 1: Forward pass for issues (segment 1)\n",
    "                issues_output = self.model(input_ids=input_ids,\n",
    "                                           attention_mask=attention_mask,\n",
    "                                           labels=issues_ids,\n",
    "                                           global_attention_mask=global_attention_mask)\n",
    "            \n",
    "                # Step 2: Forward pass for facts (segment 2)\n",
    "                facts_output = self.model(input_ids=input_ids,\n",
    "                                          attention_mask=attention_mask,\n",
    "                                          labels=facts_ids, \n",
    "                                          global_attention_mask=global_attention_mask)\n",
    "            \n",
    "                # Step 3: Forward pass for rulings (segment 3)\n",
    "                rulings_output = self.model(input_ids=input_ids,\n",
    "                                            attention_mask=attention_mask,\n",
    "                                            labels=rulings_ids,\n",
    "                                            global_attention_mask=global_attention_mask)\n",
    "            \n",
    "                # Sum up all losses and backpropagate\n",
    "                loss = issues_output.loss + facts_output.loss + rulings_output.loss\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update weights and reset gradients\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Accumulate the loss for the epoch\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Log metrics for this step\n",
    "                print(f\"Global Step {global_step}, Loss: {loss.item()}\")\n",
    "\n",
    "            # Epoch-level logging\n",
    "            epoch_time = time.time() - start_time  # Time for the entire epoch\n",
    "            avg_loss = epoch_loss / len(self.dataloader)  # Average loss for the epoch\n",
    "            steps_per_second = global_step / epoch_time  # Steps processed per second\n",
    "            samples_per_second = (global_step * self.dataloader.batch_size) / epoch_time\n",
    "            \n",
    "            # Estimated FLOPs (can be complex to calculate exactly, so this is simplified)\n",
    "            total_flos = global_step * input_ids.numel() * 2  # Example FLOPs (simplified estimate)\n",
    "            \n",
    "            # Print epoch-level summary\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs}, Avg Loss: {avg_loss}\")\n",
    "            print(f\"TrainOutput(global_step={global_step}, \"\n",
    "                  f\"training_loss={avg_loss}, \"\n",
    "                  f\"metrics={{'train_runtime': {epoch_time:.4f}, \"\n",
    "                  f\"'train_samples_per_second': {samples_per_second:.4f}, \"\n",
    "                  f\"'train_steps_per_second': {steps_per_second:.4f}, \"\n",
    "                  f\"'total_flos': {total_flos:.2f}, \"\n",
    "                  f\"'train_loss': {avg_loss}, \"\n",
    "                  f\"'epoch': {epoch + 1}}})\")\n",
    "            torch.cuda.empty_cache()  # Clear cache after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96031ffa-e72f-4404-ad69-f0cd103c8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeller = modelling(ready_model, ready_tokenizer, ready_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99970ead-3e1e-4a16-a46a-45d3c73217d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeller.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361dbd8-b9be-4a4d-868c-49f037c75eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
