{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d90f0e-ab87-42e4-86c1-4477c3ebf103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from TopicSegmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c950961-1086-479e-87eb-afeda10a5922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize LegalBert instance\n",
    "legal_bert = LegalBert()\n",
    "\n",
    "# Load the model\n",
    "loaded_seq2seq_model = tf.keras.models.load_model('seq2seq_model.h5')\n",
    "\n",
    "# Sample Data\n",
    "input_text = \"Blue na mama a tambay at FYI Corporation filed a lawsuit on August in Compound\"\n",
    "\n",
    "# Prepare data\n",
    "tokens legal_bert.tokenizer(input_text, return_tensors='pt', truncation=True, padding=True, max_length=16384)\n",
    "\n",
    "# Predict\n",
    "predictions = loaded_seq2seq_model.predict(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a146e43e-f97f-45d5-89ff-b4fe3fdaddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4891e1f4-f88b-4702-bad9-e85d036675cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding,\n",
    "    Dropout,\n",
    "    LayerNormalization,\n",
    "    Dense,\n",
    "    MultiHeadAttention,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c9749da-69ca-4a18-9778-4821b854fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedStandardDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_heads, ff_dim, dropout_rate=0.1, **kwargs):\n",
    "        super(ModifiedStandardDecoder, self).__init__(**kwargs)\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.positional_encoding = PositionalEncoding(embedding_dim)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "        self.masked_self_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, dropout=dropout_rate)\n",
    "        self.layer_norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.multihead_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim, dropout=dropout_rate)\n",
    "        self.layer_norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(embedding_dim)\n",
    "        ])\n",
    "        self.layer_norm3 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout3 = Dropout(dropout_rate)\n",
    "        self.dense = Dense(vocab_size)\n",
    "        self.softmax = tf.keras.activations.softmax\n",
    "\n",
    "    def call(self, ruling, issues, facts, encoder_outputs, padding_mask=None):\n",
    "        # Text embedding layer\n",
    "        embedded_ruling = self.embedding(ruling)\n",
    "        embedded_issues = self.embedding(issues)\n",
    "        embedded_facts = self.embedding(facts)\n",
    "\n",
    "        # Dropout\n",
    "        embedded_ruling = self.dropout1(embedded_ruling)\n",
    "        embedded_issues = self.dropout1(embedded_issues)\n",
    "        embedded_facts = self.dropout1(embedded_facts)\n",
    "\n",
    "        # Positional encoding\n",
    "        embedded_ruling = self.positional_encoding(embedded_ruling)\n",
    "        embedded_issues = self.positional_encoding(embedded_issues)\n",
    "        embedded_facts = self.positional_encoding(embedded_facts)\n",
    "\n",
    "        # Dropout\n",
    "        embedded_ruling = self.dropout2(embedded_ruling)\n",
    "\n",
    "        print(embedded_ruling)\n",
    "        \n",
    "        # Create look-ahead mask\n",
    "        seq_len = tf.shape(ruling)[1]\n",
    "        look_ahead_mask = self.create_look_ahead_mask(seq_len)\n",
    "        look_ahead_mask = tf.convert_to_tensor(look_ahead_mask, dtype=tf.float32)\n",
    "        look_ahead_mask = look_ahead_mask[tf.newaxis, tf.newaxis, :, :]  # Shape: (1, 1, seq_len, seq_len)\n",
    "\n",
    "        # Masked multi-head self-attention\n",
    "        attention_output = self.masked_self_attention(query=embedded, key=embedded, value=embedded, attention_mask=look_ahead_mask)\n",
    "\n",
    "        # Layer normalization\n",
    "        attention_output = self.layer_norm1(attention_output + embedded)\n",
    "\n",
    "        # Multi-head attention with encoder output\n",
    "        output = self.multihead_attention(query=attention_output, key=encoder_outputs, value=encoder_outputs, attention_mask=padding_mask)\n",
    "\n",
    "        # Layer normalization\n",
    "        output = self.layer_norm2(output + attention_output)\n",
    "\n",
    "        # Feed-forward network\n",
    "        ffn_output = self.ffn(output)\n",
    "\n",
    "        # Layer normalization\n",
    "        ffn_output = self.layer_norm3(ffn_output + output)\n",
    "\n",
    "        # Dropout\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "\n",
    "        # Dense layer\n",
    "        logits = self.dense(ffn_output)\n",
    "\n",
    "        # Softmax\n",
    "        predictions = self.softmax(logits)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def create_look_ahead_mask(self, size):\n",
    "        mask = tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "        return mask\n",
    "\n",
    "    def save(self,filename):\n",
    "        self.model.save('bert_model_{}.h5'.format(filename))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ModifiedStandardDecoder, self).get_config()\n",
    "        config.update({\n",
    "            \"vocab_size\": self.embedding.input_dim,\n",
    "            \"embedding_dim\": self.embedding.output_dim,\n",
    "            \"num_heads\": self.masked_self_attention.num_heads,\n",
    "            \"ff_dim\": self.ffn.layers[0].units,\n",
    "            \"dropout_rate\": self.dropout1.rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(max_len, d_model)\n",
    "        \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
    "        # Apply sin to even positions and cos to odd positions\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123acc60-9a11-4504-94de-df49c656a382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdfl0\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:188: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Tensor(\"positional_encoding_1/add:0\", shape=(None, None, 768), dtype=float32)\n",
      "Tensor(\"positional_encoding_1/add:0\", shape=(None, None, 768), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ modified_standard_decoder     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8000</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">50,875,456</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ModifiedStandardDecoder</span>)     │                           │                 │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ modified_standard_decoder     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8000\u001b[0m)        │      \u001b[38;5;34m50,875,456\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│ (\u001b[38;5;33mModifiedStandardDecoder\u001b[0m)     │                           │                 │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,875,456</span> (194.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,875,456\u001b[0m (194.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,875,456</span> (194.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,875,456\u001b[0m (194.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_size = 8000\n",
    "embedding_dim = 768\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "dropout_rate = 0.1\n",
    "\n",
    "decoder = ModifiedStandardDecoder(vocab_size, embedding_dim, num_heads, ff_dim, dropout_rate)\n",
    "\n",
    "annotated_inputs = tf.keras.Input(shape=(None,))\n",
    "encoder_outputs = tf.keras.Input(shape=(None, embedding_dim))\n",
    "\n",
    "padding_mask = None  # Add padding mask if necessary\n",
    "\n",
    "outputs = decoder(annotated_inputs, encoder_outputs, padding_mask=padding_mask)\n",
    "model = tf.keras.Model(inputs=[annotated_inputs, encoder_outputs], outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a51c5-b55c-4623-8ad6-8aee08350d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769ec8d-2d18-4c3c-818d-18b095aface5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c444dd5-c968-43b8-ab08-ee0f043d8b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca81a1-a50d-47fb-a55b-e0287c319191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd07d16e-b605-443d-9184-6dee6455eb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa49112-19f4-4a1f-a4eb-a6a98cc82134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdfl0\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:188: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Tensor(\"positional_encoding_1/add:0\", shape=(None, None, 768), dtype=float32)\n",
      "Tensor(\"positional_encoding_1/add:0\", shape=(None, None, 768), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ modified_standard_decoder     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8000</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">50,875,456</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ModifiedStandardDecoder</span>)     │                           │                 │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ modified_standard_decoder     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8000\u001b[0m)        │      \u001b[38;5;34m50,875,456\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│ (\u001b[38;5;33mModifiedStandardDecoder\u001b[0m)     │                           │                 │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,875,456</span> (194.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,875,456\u001b[0m (194.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,875,456</span> (194.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,875,456\u001b[0m (194.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from TopicSegmentation import LegalBert, ModifiedStandardDecoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "# Example usage\n",
    "vocab_size = 8000\n",
    "embedding_dim = 768\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "dropout_rate = 0.1\n",
    "\n",
    "decoder = ModifiedStandardDecoder(vocab_size, embedding_dim, num_heads, ff_dim, dropout_rate)\n",
    "\n",
    "annotated_inputs = tf.keras.Input(shape=(None,))\n",
    "encoder_outputs = tf.keras.Input(shape=(None, embedding_dim))\n",
    "\n",
    "padding_mask = None  # Add padding mask if necessary\n",
    "\n",
    "outputs = decoder(annotated_inputs, encoder_outputs, padding_mask=padding_mask)\n",
    "model = tf.keras.Model(inputs=[annotated_inputs, encoder_outputs], outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "604b994b-9110-4869-930c-02f204ddfcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "court case    0\n",
      "facts         0\n",
      "issues        0\n",
      "rulings       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>court case</th>\n",
       "      <th>facts</th>\n",
       "      <th>issues</th>\n",
       "      <th>rulings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECOND DIVISION\\n[ G.R. No. 101798. ]\\nPEOPLE ...</td>\n",
       "      <td>on or about October 19, 1989 in the municipali...</td>\n",
       "      <td>In this appeal, appellant assigns two errors s...</td>\n",
       "      <td>Accordingly, in light of the foregoing statuto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G.R. No. L-49823\\nTHIRD DIVISION\\n[ G.R. No. L...</td>\n",
       "      <td>On 30 September 1977, the City Court of Manila...</td>\n",
       "      <td>Whether the City Court of Manila has the juris...</td>\n",
       "      <td>This petition is impressed with merit.\\r\\n\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G.R. No. L-27120\\r\\n[ G.R. No. L-27120. ]\\r\\nT...</td>\n",
       "      <td>Petition for certiorari against the order of t...</td>\n",
       "      <td>is it correct to say that the respondent judge...</td>\n",
       "      <td>The declara­tions constitute judicial admissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THIRD DIVISION\\n[ G.R. Nos. 255324 &amp; 255353. A...</td>\n",
       "      <td>Via this Petition for Review on Certiorari,[1]...</td>\n",
       "      <td>Through the instant Petition, petitioner raise...</td>\n",
       "      <td>On April 22, 2005, respondent filed with the C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FIRST DIVISION\\n[ G.R. No. 238714. August 30, ...</td>\n",
       "      <td>Respondents claim ownership over a 51.24-squar...</td>\n",
       "      <td>Petitioner raises the sole issue of whether th...</td>\n",
       "      <td>In its November 4, 2014 Decision, the RTC decr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          court case  \\\n",
       "1  SECOND DIVISION\\n[ G.R. No. 101798. ]\\nPEOPLE ...   \n",
       "2  G.R. No. L-49823\\nTHIRD DIVISION\\n[ G.R. No. L...   \n",
       "3  G.R. No. L-27120\\r\\n[ G.R. No. L-27120. ]\\r\\nT...   \n",
       "4  THIRD DIVISION\\n[ G.R. Nos. 255324 & 255353. A...   \n",
       "5  FIRST DIVISION\\n[ G.R. No. 238714. August 30, ...   \n",
       "\n",
       "                                               facts  \\\n",
       "1  on or about October 19, 1989 in the municipali...   \n",
       "2  On 30 September 1977, the City Court of Manila...   \n",
       "3  Petition for certiorari against the order of t...   \n",
       "4  Via this Petition for Review on Certiorari,[1]...   \n",
       "5  Respondents claim ownership over a 51.24-squar...   \n",
       "\n",
       "                                              issues  \\\n",
       "1  In this appeal, appellant assigns two errors s...   \n",
       "2  Whether the City Court of Manila has the juris...   \n",
       "3  is it correct to say that the respondent judge...   \n",
       "4  Through the instant Petition, petitioner raise...   \n",
       "5  Petitioner raises the sole issue of whether th...   \n",
       "\n",
       "                                             rulings  \n",
       "1  Accordingly, in light of the foregoing statuto...  \n",
       "2  This petition is impressed with merit.\\r\\n\\r\\n...  \n",
       "3  The declara­tions constitute judicial admissio...  \n",
       "4  On April 22, 2005, respondent filed with the C...  \n",
       "5  In its November 4, 2014 Decision, the RTC decr...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_text = [\"John Doe a lawyer at ABC Corporation filed a lawsuit on January in New York City\", \n",
    "           \"Mama mo a dentist at DFC Corporation filed a lawsuit on January in New York City\"]\n",
    "\n",
    "ruling = ['John Doe a lawyer at ABC Corporation', 'Mama mo a dentist at DFC Corporation']\"\"\"\n",
    "\n",
    "df = pd.read_csv('court.csv')\n",
    "\n",
    "df = df.iloc[:,2:]\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "court_case = df['court case'].to_list()\n",
    "ruling = df['rulings'].to_list()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e58c179-15aa-44eb-b913-a95d26c7c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the preprocessor and legal BERT\n",
    "legal_bert = LegalBert()\n",
    "\n",
    "bert_output = legal_bert.get_context_vectors(court_case)\n",
    "\n",
    "\n",
    "# Tokenize the segments\n",
    "tokenizer = Tokenizer(num_words=8000)  # Adjust num_words according to your vocabulary size\n",
    "tokenizer.fit_on_texts(ruling)\n",
    "tokenized_segments = tokenizer.texts_to_sequences(ruling)\n",
    "\n",
    "max_seq_len = bert_output.shape[1]\n",
    "\n",
    "# Pad the sequences to ensure uniform length\n",
    "padded_segments = pad_sequences(tokenized_segments, padding='post', maxlen=max_seq_len)\n",
    "\n",
    "# Convert to tensor\n",
    "padded_segments = tf.convert_to_tensor(padded_segments)\n",
    "\n",
    "print(f'Legal BERT shape: {bert_output.shape}')\n",
    "print(f'Modified Decoder shape: {padded_segments.shape}')\n",
    "\n",
    "# Ensure xtrain and ytrain have the same batch size\n",
    "assert bert_output.shape[0] == padded_segments.shape[0]\n",
    "\n",
    "xtrain = bert_output.detach().numpy()\n",
    "ytrain = padded_segments\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit([ytrain, xtrain], ytrain, epochs=5)\n",
    "\n",
    "model.save('seqtoseq.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
